}
}
# scatters conditional on task+individual
# combine questMain2 and riskMain
scatter_quest_risk <- as.data.frame(right_join(questMain2,riskMain_cond_game_indiv), by=c("subjectId"))
# Scatterplots
for (i in 1:length(variables_scatter_risk_x)) {
for (j in 1:length(variables_scatter_quest_y)) {
print(ggplot(scatter_quest_risk, aes(x=scatter_quest_risk[,variables_scatter_risk_x[i]], y=scatter_quest_risk[,variables_scatter_quest_y[j]]))+
geom_point(position="jitter")+
facet_wrap(vars(task))+
theme(axis.text.y=element_blank())+
labs(x = variables_scatter_risk_x[i])+
labs(y = variables_scatter_quest_y[j])+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle(paste(variables_scatter_risk_x[i], "and", variables_scatter_quest_y[j],sep=" ")) +
theme(plot.title = element_text(size=10, face="bold"))+
theme(axis.text=element_text(size=10),
axis.title=element_text(size=10,face="bold"))+
ggsave(file=paste0("./plots/detailedScatter/","questRiskScatter","_",variables_scatter_risk_x[i],"_", variables_scatter_quest_y[j],".png"), width=6, height=4, dpi=300))
}
}
# data: combine questMain2 with mean / median allocB and skewness measure
riskmeasure_experiment = c("cond_mean_crra_upper_bound","cond_median_crra_upper_bound","cond_mean_crra_lower_bound","cond_median_crra_lower_bound","skewness","cond_mean_allocB","cond_median_allocB")
quest_risk_individual <- as.data.frame(right_join(questMain2Numeric,riskMain_conditional_investGame_crra, by=c("subjectId")))
# first set of vars
# define quest variables to be plotted (risk vars inside loop)
variables_scatter_risk_x =  riskmeasure_experiment
variables_scatter_quest_y = variables_scatter_quest_narrow
variables_scatter_risk_and_quest = c(variables_scatter_risk_x, variables_scatter_quest_y)
print(ggcorrplot(cor(quest_risk_individual[,variables_scatter_risk_and_quest], method="spearman", use = "pairwise.complete.obs"), tl.cex=6) +
ggtitle(paste("Corr CRRA BasicVars per Indiv. Quest/Exp",games_crra)))
ggsave(file=paste0("./plots/riskQuest/","CorrelationQuestExpPlotIndividualCrraBasic",games_crra,".png"), width=6, height=4, dpi=300)
# second set of vars
# define quest variables to be plotted (risk vars inside loop)
variables_scatter_risk_x =  riskmeasure_experiment
variables_scatter_quest_y = insurance_variables
variables_scatter_risk_and_quest = c(variables_scatter_risk_x, variables_scatter_quest_y)
print(ggcorrplot(cor(quest_risk_individual[,variables_scatter_risk_and_quest], method="spearman", use = "pairwise.complete.obs"), tl.cex=6) +
ggtitle(paste("Corr CRRA InsurnaceVars per Individual Quest/Exp",games_crra)))
ggsave(file=paste0("./plots/riskQuest/","CorrelationQuestExpPlotIndividualCrraInsurance",games_crra,".png"), width=6, height=4, dpi=300)
# data to use: wide data, quest_risk_individual
table_quest_risk_individual <- as.data.frame(right_join(questMain2,riskMain_conditional_investGame_crra), by=c("subjectId"))
# variables_scatter_quest_narrow
# variables: define base names risk and quest here, rest in loop
riskmeasure_experiment = c("cond_mean_crra_upper_bound","cond_median_crra_upper_bound","cond_mean_crra_lower_bound","cond_median_crra_lower_bound")
variables_correlation_quest = variables_scatter_quest_narrow
variables_correlation_risk = riskmeasure_experiment
# dataframe for corr-test results
corr_test = data.frame(var_quest=character(),
var_risk=character(),
rho=numeric(),
p_val=numeric(),
stringsAsFactors=FALSE)
# correlate allocB between all games
for (i in 1:length(variables_correlation_quest)) {
for (j in 1:length(variables_correlation_risk)) {
# filter data for probability, select relevant variables
current_data = table_quest_risk_individual %>%
select(variables_correlation_quest[i],variables_correlation_risk[j])
colnames(current_data) = c("var1","var2")
# rank correlation test
corr_test_object <- cor.test(as.numeric(current_data$var1), as.numeric(current_data$var2), method="spearman", exact=FALSE)
corr_test_loop <- as.data.frame(cbind(c(variables_correlation_quest[i]),c(variables_correlation_risk[j]), corr_test_object$estimate, c(corr_test_object$p.value)))
colnames(corr_test_loop) <- colnames(corr_test)
# save results test in dataframe
corr_test <- rbind(corr_test,corr_test_loop)
}
}
# remove rownames and print test results
rownames(corr_test) = c()
# print correlation table
# print(xtable(corr_test),title="Quest+Risk Rank Correlations + Test")
write.csv(corr_test,file="./tables/corr_allocB_questionaire_risk_crra.csv")
print("Note: -1 would mean similar riskpref in both datasets (in QUest: 1=most riskaverse, 10=least riskaverse. in Games: 1 =least riskaverse, 10=most riskaverse)")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest Risk per Individual CRRA") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
# insurance_variables
# variables: define base names risk and quest here, rest in loop
riskmeasure_experiment = c("cond_mean_crra_upper_bound","cond_median_crra_upper_bound","cond_mean_crra_lower_bound","cond_median_crra_lower_bound")
variables_correlation_quest = insurance_variables
variables_correlation_risk = riskmeasure_experiment
# dataframe for corr-test results
corr_test = data.frame(var_quest=character(),
var_risk=character(),
rho=numeric(),
p_val=numeric(),
stringsAsFactors=FALSE)
# correlate allocB between all games
for (i in 1:length(variables_correlation_quest)) {
for (j in 1:length(variables_correlation_risk)) {
# filter data for probability, select relevant variables
current_data = table_quest_risk_individual %>%
select(variables_correlation_quest[i],variables_correlation_risk[j])
colnames(current_data) = c("var1","var2")
# rank correlation test
corr_test_object <- cor.test(as.numeric(current_data$var1), as.numeric(current_data$var2), method="spearman", exact=FALSE)
corr_test_loop <- as.data.frame(cbind(c(variables_correlation_quest[i]),c(variables_correlation_risk[j]), corr_test_object$estimate, c(corr_test_object$p.value)))
colnames(corr_test_loop) <- colnames(corr_test)
# save results test in dataframe
corr_test <- rbind(corr_test,corr_test_loop)
}
}
# remove rownames and print test results
rownames(corr_test) = c()
# print correlation table
# print(xtable(corr_test),title="Quest+Risk Rank Correlations + Test")
write.csv(corr_test,file="./tables/corr_allocB_questionaire_risk_crra_insurance.csv")
print("Note: -1 would mean similar riskpref in both datasets (in QUest: 1=most riskaverse, 10=least riskaverse. in Games: 1 =least riskaverse, 10=most riskaverse)")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest(Insurance) Risk per Individual CRRA") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
# Scatter
# variables for scatters
# from quest: variables_scatter_quest_wide, variables_scatter_quest_narrow
# from riskMain:
riskmeasure_experiment = c("cond_mean_crra_upper_bound","cond_median_crra_upper_bound","cond_mean_crra_lower_bound","cond_median_crra_lower_bound","cond_mean_allocB","cond_median_allocB")
# x/y dimension: variables_scatter_quest_1=dim1, variables_scatter_quest_2=dim2)
variables_scatter_risk_x = riskmeasure_experiment
variables_scatter_quest_y = variables_scatter_quest_narrow
variables_scatter_risk_and_quest = c(variables_scatter_risk_x, variables_scatter_quest_y)
# values for probabiliy (for conditional on probability plots)
values_ph_scatter_risk_quest = probabilities
values_ph_scatter_risk_quest = values_ph_scatter_risk_quest
# correlation plots conditional on games
# first set of variables
for (i in 1:length(values_ph_scatter_risk_quest)) {
scatter_quest_risk_cond_ph <- as.data.frame(right_join(questMain2Numeric,riskMain_cond_game_indiv_prob_crra), by=c("subjectId")) %>%
filter(ph==values_ph_scatter_risk_quest[i])
print(ggcorrplot(cor(scatter_quest_risk_cond_ph[,variables_scatter_risk_and_quest], method="spearman", use = "pairwise.complete.obs"), tl.cex=6) +
ggtitle(paste("Corr Quest/Exp Crra",games_crra,", p=",values_ph_scatter_risk_quest[i])))
ggsave(file=paste0("./plots/riskQuest/","CorrelationQuestExpPlotCrraBasic",games_crra,"ph",values_ph_scatter_risk_quest[i],".png"), width=6, height=4, dpi=300)
}
# second set of variables
variables_scatter_risk_x = riskmeasure_experiment
variables_scatter_quest_y = insurance_variables
variables_scatter_risk_and_quest = c(variables_scatter_risk_x, variables_scatter_quest_y)
for (i in 1:length(values_ph_scatter_risk_quest)) {
scatter_quest_risk_cond_ph <- as.data.frame(right_join(questMain2Numeric,riskMain_cond_game_indiv_prob_crra), by=c("subjectId")) %>%
filter(ph==values_ph_scatter_risk_quest[i])
print(ggcorrplot(cor(scatter_quest_risk_cond_ph[,variables_scatter_risk_and_quest], method="spearman", use = "pairwise.complete.obs"), tl.cex=6) +
ggtitle(paste("Corr Insurance Quest/Exp Crra",games_crra,", p=",values_ph_scatter_risk_quest[i])))
ggsave(file=paste0("./plots/riskQuest/","questCorrelationPlotCrraInsurance",games_crra,"ph",values_ph_scatter_risk_quest[i],".png"), width=6, height=4, dpi=300)
}
# data: combine quest and risk
quest_risk <- as.data.frame(right_join(questMain2,riskMain_cond_game_indiv_prob_crra), by=c("subjectId"))
# conditional probabilities for correlation
corr_probabilities = probabilities
corr_probabilities = corr_probabilities
# for variables_scatter_quest_narrow
# variables for correlation
riskmeasure_experiment = c("cond_mean_crra_upper_bound","cond_median_crra_upper_bound","cond_mean_crra_lower_bound","cond_median_crra_lower_bound")
variables_correlation_quest = variables_scatter_quest_narrow
variables_correlation_risk = riskmeasure_experiment
# dataframe for corr-test results
corr_test = data.frame(prob=numeric(),
var_quest=character(),
var_risk=character(),
rho=numeric(),
p_val=numeric(),
stringsAsFactors=FALSE)
# correlate allocB between all games
for (i in 1:length(variables_correlation_quest)) {
for (j in 1:length(variables_correlation_risk)) {
for (h in 1:length(corr_probabilities)) {
# filter data for probability, select relevant variables
current_data = filter(quest_risk, ph==corr_probabilities[h]) %>%
select(variables_correlation_quest[i],variables_correlation_risk[j])
colnames(current_data) = c("var1","var2")
# rank correlation test
corr_test_object <- cor.test(as.numeric(current_data$var1), as.numeric(current_data$var2), method="spearman", exact=FALSE)
corr_test_loop <- as.data.frame(cbind(c(corr_probabilities[h]),c(variables_correlation_quest[i]),c(variables_correlation_risk[j]), corr_test_object$estimate, c(corr_test_object$p.value)))
colnames(corr_test_loop) <- colnames(corr_test)
# save results test in dataframe
corr_test <- rbind(corr_test,corr_test_loop)
}
}
}
# remove rownames and print test results
rownames(corr_test) = c()
# print correlation table
# print(xtable(corr_test),title="Quest+Risk Rank Correlations + Test")
write.csv(corr_test,file="./tables/corr_allocB_questionaire_conditional_on_p_crra.csv")
print("Note: -1 would mean similar riskpref in both datasets (in QUest: 1=most riskaverse, 10=least riskaverse. in Games: 1 =least riskaverse, 10=most riskaverse)")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","","","","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest AllocB Crra") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
# for insurance_variables
# variables for correlation
riskmeasure_experiment = c("cond_mean_crra_upper_bound","cond_median_crra_upper_bound","cond_mean_crra_lower_bound","cond_median_crra_lower_bound")
variables_correlation_quest = insurance_variables
variables_correlation_risk = riskmeasure_experiment
# dataframe for corr-test results
corr_test = data.frame(prob=numeric(),
var_quest=character(),
var_risk=character(),
rho=numeric(),
p_val=numeric(),
stringsAsFactors=FALSE)
# correlate allocB between all games
for (i in 1:length(variables_correlation_quest)) {
for (j in 1:length(variables_correlation_risk)) {
for (h in 1:length(corr_probabilities)) {
# filter data for probability, select relevant variables
current_data = filter(quest_risk, ph==corr_probabilities[h]) %>%
select(variables_correlation_quest[i],variables_correlation_risk[j])
colnames(current_data) = c("var1","var2")
# rank correlation test
corr_test_object <- cor.test(as.numeric(current_data$var1), as.numeric(current_data$var2), method="spearman", exact=FALSE)
corr_test_loop <- as.data.frame(cbind(c(corr_probabilities[h]),c(variables_correlation_quest[i]),c(variables_correlation_risk[j]), corr_test_object$estimate, c(corr_test_object$p.value)))
colnames(corr_test_loop) <- colnames(corr_test)
# save results test in dataframe
corr_test <- rbind(corr_test,corr_test_loop)
}
}
}
# remove rownames and print test results
rownames(corr_test) = c()
# print correlation table
# print(xtable(corr_test),title="Quest+Risk Rank Correlations + Test")
write.csv(corr_test,file="./tables/corr_allocB_questionaire_conditional_on_p_crra_insurance.csv")
print("Note: -1 would mean similar riskpref in both datasets (in QUest: 1=most riskaverse, 10=least riskaverse. in Games: 1 =least riskaverse, 10=most riskaverse)")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","","","","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest(Insurance) AllocB Crra") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
# setwd
setwd("C:/Users/eriks/Desktop/FGN_Arbeit")
# For non-nix users (as defined in `./shell.nix`)
library(tidyverse)
library(kableExtra) # tables•
library(skimr) # decriptive stats
library(gridExtra)
library(GGally)
library(xtable)
library(caret)
library(shape)
library(tikzDevice)
library(cleandata)
library(ggcorrplot)
library(psych)
options(xtable.comment = FALSE,
digits = 6)
knitr::opts_chunk$set( dev="pdf"
, external=TRUE
, fig.width=7
, fig.height=4
, fig.path="./assets/figs/"
, cache=FALSE
, echo=FALSE
, warning=TRUE
, message=FALSE
, tidy=TRUE
, cache=TRUE
, fig.align="center"
, fig.pos="!hbt"
)
filter <- dplyr::filter
select <- dplyr::select
corr_test = read.csv(file="./tables/corr_allocB_questionaire_risk.csv")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest AllocB") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
corr_test = read.csv(file="./tables/corr_allocB_questionaire_conditional_on_p.csv")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest AllocB Conditional on P") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
corr_test = read.csv(file="./tables/corr_allocB_questionaire_risk_crra.csv")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest Crra") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
# setwd
setwd("C:/Users/eriks/Desktop/FGN_Arbeit")
# For non-nix users (as defined in `./shell.nix`)
library(tidyverse)
library(kableExtra) # tables•
library(skimr) # decriptive stats
library(gridExtra)
library(GGally)
library(xtable)
library(caret)
library(shape)
library(tikzDevice)
library(cleandata)
library(ggcorrplot)
library(psych)
options(xtable.comment = FALSE,
digits = 6)
knitr::opts_chunk$set( dev="pdf"
, external=TRUE
, fig.width=7
, fig.height=4
, fig.path="./assets/figs/"
, cache=FALSE
, echo=FALSE
, warning=TRUE
, message=FALSE
, tidy=TRUE
, cache=TRUE
, fig.align="center"
, fig.pos="!hbt"
)
filter <- dplyr::filter
select <- dplyr::select
corr_test = read.csv(file="./tables/corr_allocB_questionaire_risk.csv")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest AllocB") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
corr_test = read.csv(file="./tables/corr_allocB_questionaire_conditional_on_p.csv")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest AllocB Conditional on P") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
corr_test = read.csv(file="./tables/corr_allocB_questionaire_risk_crra.csv")
kable(corr_test, "latex", booktabs = TRUE, linesep = c("", "","",
"\\addlinespace"), longtable = TRUE, caption = "Correlations Quest Crra") %>%
kable_styling(latex_options = c("hold_position", "repeat_header"))
library(readr)
beliefsAmbiguityMain <- read_csv("C:/Users/eriks/Desktop/FGN_Arbeit/data/clean/beliefsAmbiguityMain.csv")
View(beliefsAmbiguityMain)
library(readr)
questAmbiguityMain <- read_csv("C:/Users/eriks/Desktop/FGN_Arbeit/data/clean/questAmbiguityMain.csv")
View(questAmbiguityMain)
library(readr)
OxCGRT_Download_290420_082555_Full <- read_csv("C:/Users/eriks/Desktop/MiQE_F/Big_Data_Analytics/project/lockdown_measures/OxCGRT_Download_290420_082555_Full.csv")
View(OxCGRT_Download_290420_082555_Full)
install.packages("SparkR)")
# univariate garch models
#### Pre
# librarys
library(readxl)
library(readr)
library(data.table)
library(tidyverse)
library(stats)
library(ggfortify)
library(zoo)
library(xtable)
library(lubridate)
library(forecast)
library(tseries)
library(xts)
library(quantmod)
library(fGarch)
library(rugarch)
library(rmgarch)
library(psych)
library(MASS)
filter <- dplyr::filter
select <- dplyr::select
setwd("~/GitHub/Volatile-Gamma") # setwd
source("scripts/functions.R") # functions
source("scripts/garchFunction.R") # functions
outpathDescriptive = "output/univariateDescriptives/"
outpathModels =  "output/univariateModels/"
# Import Data ----
garch_data_ts_r  = readRDS("output/univariateDescriptives/garch_data_ts_r.rds") # selected garch data after struc break analysis
garch_data_ts_r_errors = garch_data_ts_r[,c("rub_errors", "oil_errors")]
# Tree GARCH (1,1) ----
# 1) define data inputs
# define possible split variables
# past returns, epsilons, variances of own process and other processes
means = colMeans(garch_data_ts_r_errors)
epsilon = sweep(garch_data_ts_r_errors,2,means)
epsilon_sq = epsilon^2
colnames(epsilon) = paste0(colnames(garch_data_ts_r_errors),"_epsilon")
colnames(epsilon_sq) = paste0(colnames(garch_data_ts_r_errors),"_epsilon_sq")
base_split_variables = as.xts(cbind(epsilon, epsilon_sq)) #dataset split variables
# get 2 lags of each variable. In VAR tests, dependencies were not consistent above the 2nd lag. Are excluded to get parsimonious computationally feasible model
max_lags = 3 # ! keep at 1+lags used. number lags for loop such that for all  split vars the same dataset is used (NA in the first observations otherwise)
lag1 = lag(base_split_variables,1)
lag2 = lag(base_split_variables,2)
colnames(lag1) = paste0(colnames(base_split_variables),"_lag1")
colnames(lag2) = paste0(colnames(base_split_variables),"_lag2")
split_variables = as.data.frame(cbind(lag1 , lag2)) # data frame instead of time series
split_variables$date = rownames(split_variables)
vector_quantiles = seq(1, 7)*0.125 # quantiles as threshholds
# list for splitting variables
list_split_variables = colnames(split_variables)[colnames(split_variables) !="date"] # cols as splitting variables
# return series used
returns = as.data.frame(garch_data_ts_r_errors$rub_errors)
returns$date = rownames(returns)
colnames(returns) = c("return","date")
treeGarchResult =   buildAndPruneTree(returns, split_variables, list_split_variables, max_lags)
treeGarchResult
returns_df= returns
split_variables_df = split_variables
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
split_covariate = select(split_variables_df,treeGarchResult$split_order_pruned$split_variable1[1])
head(split_covariate)
treeGarchResult$split_order_pruned$split_variable1[1]
split_covariate = select(split_variables_df,returns,treeGarchResult$split_order_pruned$split_variable1[1])
colnames(split_covariate) = c("return","selected_covariate")
View(split_variables_df)
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
View(split_data)
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
split_covariate = select(split_variables_df,return,treeGarchResult$split_order_pruned$split_variable1[1])
split_data
head(split_data)
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
#split_covariate = select(split_variables_df,return,treeGarchResult$split_order_pruned$split_variable1[1])
split_covariate = split_covariate[,c("return",treeGarchResult$split_order_pruned$split_variable1[1]) %in% colnames(split_covariate)]
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
c("return",treeGarchResult$split_order_pruned$split_variable1[1]) %in% colnames(split_covariate)
colnames(split_covariate)
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
colnames(split_data)
split_covariate = split_covariate[,c("return",treeGarchResult$split_order_pruned$split_variable1[1]) %in% colnames(split_covariate)]
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
#split_covariate = select(split_variables_df,return,treeGarchResult$split_order_pruned$split_variable1[1])
split_covariate_test = split_covariate[,c("return",treeGarchResult$split_order_pruned$split_variable1[1]) %in% colnames(split_covariate)]
split_covariate_test
c("return",treeGarchResult$split_order_pruned$split_variable1[1]) %in% colnames(split_covariate)
split_covariate
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
split_covariate_test = split_data[,c("return",treeGarchResult$split_order_pruned$split_variable1[1]) %in% colnames(split_data)]
View(split_covariate_test)
c("return",treeGarchResult$split_order_pruned$split_variable1[1]) %in% colnames(split_data)
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
split_covariate_test = split_data[,colnames(split_data) %in% c("return",treeGarchResult$split_order_pruned$split_variable1[1])]
View(split_covariate_test)
treeGarchResult$split_order_pruned
#### Pre
# librarys
library(readxl)
library(readr)
library(data.table)
library(tidyverse)
library(stats)
library(ggfortify)
library(zoo)
library(xtable)
library(lubridate)
library(forecast)
library(tseries)
library(xts)
library(quantmod)
library(fGarch)
library(rugarch)
library(rmgarch)
library(psych)
library(MASS)
filter <- dplyr::filter
select <- dplyr::select
setwd("~/GitHub/Volatile-Gamma") # setwd
source("scripts/functions.R") # functions
source("scripts/garchFunction.R") # functions
outpathDescriptive = "output/univariateDescriptives/"
outpathModels =  "output/univariateModels/"
# Import Data ----
garch_data_ts_r  = readRDS("output/univariateDescriptives/garch_data_ts_r.rds") # selected garch data after struc break analysis
garch_data_ts_r_errors = garch_data_ts_r[,c("rub_errors", "oil_errors")]
# Tree GARCH (1,1) ----
# 1) define data inputs
# define possible split variables
# past returns, epsilons, variances of own process and other processes
means = colMeans(garch_data_ts_r_errors)
epsilon = sweep(garch_data_ts_r_errors,2,means)
epsilon_sq = epsilon^2
colnames(epsilon) = paste0(colnames(garch_data_ts_r_errors),"_epsilon")
colnames(epsilon_sq) = paste0(colnames(garch_data_ts_r_errors),"_epsilon_sq")
base_split_variables = as.xts(cbind(epsilon, epsilon_sq)) #dataset split variables
# get 2 lags of each variable. In VAR tests, dependencies were not consistent above the 2nd lag. Are excluded to get parsimonious computationally feasible model
max_lags = 3 # ! keep at 1+lags used. number lags for loop such that for all  split vars the same dataset is used (NA in the first observations otherwise)
lag1 = lag(base_split_variables,1)
lag2 = lag(base_split_variables,2)
colnames(lag1) = paste0(colnames(base_split_variables),"_lag1")
colnames(lag2) = paste0(colnames(base_split_variables),"_lag2")
split_variables = as.data.frame(cbind(lag1 , lag2)) # data frame instead of time series
split_variables$date = rownames(split_variables)
vector_quantiles = seq(1, 7)*0.125 # quantiles as threshholds
# list for splitting variables
list_split_variables = colnames(split_variables)[colnames(split_variables) !="date"] # cols as splitting variables
# return series used
returns = as.data.frame(garch_data_ts_r_errors$rub_errors)
returns$date = rownames(returns)
colnames(returns) = c("return","date")
treeGarchResult =   buildAndPruneTree(returns, split_variables, list_split_variables, max_lags)
treeGarchResult$split_order_pruned
returns_df= returns
split_variables_df = split_variables
# first split
# check if split was done
if(treeGarchResult$split_order_pruned$split_variable1=="split_removed"){
print("No first split")
} else {
# select data
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
split_covariate = split_data[,colnames(split_data) %in% c("return",treeGarchResult$split_order_pruned$split_variable1[1])]
colnames(split_covariate) = c("return","selected_covariate")
if(treeGarchResult$split_order_pruned$higher_lower1 == "lower") {
sample = filter(split_covariate, selected_covariate < treeGarchResult$split_order_pruned$treshhold)
} else {
sample = filter(split_covariate, selected_covariate >= treeGarchResult$split_order_pruned$treshhold)
}
sample
# check if split was done
if(treeGarchResult$split_order_pruned$split_variable1=="split_removed"){
print("No first split")
} else {
# select data
split_data = select(left_join(returns_df, split_variables_df, by="date"), -c("date"))
split_covariate = split_data[,colnames(split_data) %in% c("return",treeGarchResult$split_order_pruned$split_variable1[1])]
colnames(split_covariate) = c("return","selected_covariate")
if(treeGarchResult$split_order_pruned$higher_lower1 == "lower") {
sample = filter(split_covariate, selected_covariate < treeGarchResult$split_order_pruned$treshhold)
} else {
sample = filter(split_covariate, selected_covariate >= treeGarchResult$split_order_pruned$treshhold)
}}
s
saga
